# ToxicCommentGuard: Advanced Toxic Comment Detection & Insights Platform
## Objectives:
- Toxic Comment Detection: Automatically classify whether a comment is toxic or non-toxic using supervised machine learning models.
- Comment Categorization: Identify sub-types of toxicity such as insult, obscene, identity hate, threat, etc.

## Project Description:
    ToxicCommentGuard is a machine learning-powered web application designed to detect and analyze toxic language in user-generated comments. The project aims to create a safer and more respectful digital environment by identifying offensive content and providing insights into toxic behavior patterns. Built using Python, the platform leverages Natural Language Processing (NLP) techniques to classify them.
